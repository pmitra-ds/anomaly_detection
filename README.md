# anomaly_detection with credit card data
In this project we dive into anomaly or fraud detection with the  kaggle credit card dataset (source:). The datafile contains 26 features including amount of money spent for each user, a timing information of the trasaction and many other sensitive user information which are presented in an abstract way via PCA trasformation to protect privacy isssues. One point to stress here is that, the dataset is highly imbalanced, with the ratio of fraud to valid data about 0.17%, this makes the classification problem extremely challenging.

Before jumping into building models, first let's have a look at the data, where the amount of money spent is plotted against all the other features for the two classes. It appears that the transaction time does not provide imporant insight for the class separation, but other parameters like V11,V12,V16 seem to have clear separation between the two classes.  
![Example Figure](example.gif) 


Next, we build the ML models for anomaly detection, using two  popular models- OneclasasSVM and isolation forest. Although, the accuracy in both models are above 95% it would be errorneous to look at accuracy as a performance matrix for an anomaly detection task. Looking at the precision and recall would be a better choice. For one class SVM, it is seen that for the majority clas  recall=0, precision=0.99, and for te minority (fraud) class precision =0, recall= 0.99. This tells us, the classifier is very good at NOT flagging a fraud event as a valid one (false negative ~0), but it produces a lot of false positives, i.e. flagging a significant number of valid cases as frauds. For the isolation forest the situation is kind of opposite. For the majority class
recall =precision = 1, but for the minority class recall =0.37, precision =0.34. There, the classifier is good at not producing false positives, but at the cost of loosing sensitivity to many of the actual fraud events.

Since the performance of the methods are not satisfactory, we try resampling to 'cure' the imbalance a bit. the training set is resampled- where the majority class is downsampled, and the minority class is upsampled. This resulted in for the oneclassSVM model, 18% increase in precision for the majority class, with a small decrease in recall for minority class, making little less number of false positives than before. For the isolation forest, the recall for minority class improved almost twice than before. 

It is hard to comment which of the model is better, depends on the purpose. If we want to have absolute zero tolerance for the actual fraud cases recognized as valid cases, oneclass SVM seems a better choice, however, it will come at the cost of  having a lot of 'false alarm' where valid cases are registered as frauds. But none of the models seem to have achieved the goal to their fullest potential, it might be good to explore better resampling methods, or apply more sophisticated methods involving Deep Learning.
